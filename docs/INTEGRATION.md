<!-- version: 1.2 | updated: 2026-02-21 -->

# Butt-Dial MCP — Integration Guide

Give your AI agent a phone number. This guide covers everything you need to register, get a token, send your first message, and go live.

---

## 1. What This Is

Butt-Dial is an open-source MCP server that gives AI agents full communication abilities — phone calls, SMS, email, and WhatsApp. Your agent connects via SSE or REST, discovers tools, and starts making calls and sending messages. The server handles all the plumbing (Twilio, Resend, TTS) so your agent just talks.

---

## 2. Quick Start (5 Steps)

### Step 1: Install & Run

```bash
git clone https://github.com/elrad/butt-dial-mcp.git
cd butt-dial-mcp
npm install
cp .env.example .env
npm run build
node dist/index.js
```

The server starts on `http://localhost:3100`.

### Step 2: Register

Visit `http://localhost:3100/auth/login` and click **Register**. Fill in:
- Email
- Password (min 8 characters)
- Account name

Verify with the 6-digit code sent to your email. In demo mode (`DEMO_MODE=true`), the code is printed to the server console.

### Step 3: Get Your API Token

After login, go to `http://localhost:3100/admin`. Your API token is displayed at the top of the dashboard. Click **Copy** to grab it.

### Step 4: Send Your First Message

```bash
# With an agent token, agentId is auto-detected — you don't need to pass it:
curl -X POST http://localhost:3100/api/v1/send-message \
  -H "Authorization: Bearer YOUR_AGENT_TOKEN" \
  -H "Content-Type: application/json" \
  -d '{
    "to": "+15559876543",
    "body": "Hello from my AI agent!",
    "channel": "sms"
  }'
```

In sandbox mode, this uses mock providers — no real SMS is sent, but you get a realistic response.

### Step 5: Check for Waiting Messages

```bash
curl http://localhost:3100/api/v1/waiting-messages?agentId=test-agent-001 \
  -H "Authorization: Bearer YOUR_TOKEN"
```

This returns any messages that couldn't be delivered while your agent was offline. Fetching acknowledges them automatically.

If an LLM key is configured (Anthropic, OpenAI, or custom), sandbox sends also generate a simulated reply after ~2 seconds.

---

## 3. Authentication

### Token Types

| Token | Who Uses It | How to Get It | What It Accesses |
|-------|-------------|---------------|------------------|
| **Org Token** | Developers | Registration or admin panel | Admin panel, provisioning, org-level APIs |
| **Agent Token** | AI agents | Returned by provisioning | MCP tools, REST API, scoped to one agent |
| **Orchestrator Token** | Super-admins | `.env` file | All orgs, all agents (optional) |

### Using Your Token

**REST API:**
```
Authorization: Bearer YOUR_TOKEN
```

**MCP (SSE):**
```
GET http://localhost:3100/sse?token=YOUR_TOKEN&agentId=YOUR_AGENT_ID
```

---

## 4. Sandbox Mode

New accounts start in **sandbox mode**. All API calls work, but use mock providers — no real messages, no costs.

### What Happens in Sandbox

- SMS, email, WhatsApp, LINE all return realistic responses with Twilio-format IDs
- Calls return `queued` status with realistic call SIDs
- Usage tracking and compliance checks run normally
- No message content is stored (privacy-first — only usage logs track action counts)

### LLM-Powered Reply Simulation

If any LLM key is configured, sandbox sends automatically generate a simulated reply:

1. You send a message via API
2. After ~2 seconds, a realistic reply appears as an inbound message
3. The reply is generated by the LLM, acting as the recipient

Supported LLM providers (auto-detected from config):
- `ANTHROPIC_API_KEY` → Claude Haiku
- `OPENAI_API_KEY` → GPT-4o-mini
- `SANDBOX_LLM_ENDPOINT` → Any OpenAI-compatible API (Ollama, LM Studio, Together, Groq)

Set `SANDBOX_LLM_ENABLED=false` to disable.

---

## 5. REST API

All endpoints are at `/api/v1/`. Full interactive docs at `/admin#docs`.

### Send a Message

```bash
# SMS
curl -X POST http://localhost:3100/api/v1/send-message \
  -H "Authorization: Bearer TOKEN" \
  -H "Content-Type: application/json" \
  -d '{"agentId":"my-agent","to":"+15559876543","body":"Hello!","channel":"sms"}'

# Email
curl -X POST http://localhost:3100/api/v1/send-message \
  -H "Authorization: Bearer TOKEN" \
  -H "Content-Type: application/json" \
  -d '{"agentId":"my-agent","to":"user@example.com","body":"Hello!","channel":"email","subject":"Hi"}'

# WhatsApp
curl -X POST http://localhost:3100/api/v1/send-message \
  -H "Authorization: Bearer TOKEN" \
  -H "Content-Type: application/json" \
  -d '{"agentId":"my-agent","to":"+15559876543","body":"Hello!","channel":"whatsapp"}'
```

### Make a Voice Call

```bash
curl -X POST http://localhost:3100/api/v1/make-call \
  -H "Authorization: Bearer TOKEN" \
  -H "Content-Type: application/json" \
  -d '{"agentId":"my-agent","to":"+15559876543","greeting":"Hello!"}'
```

### Get Waiting Messages

```bash
# Fetch messages that arrived while your agent was offline (auto-acknowledges on fetch)
curl http://localhost:3100/api/v1/waiting-messages?agentId=my-agent \
  -H "Authorization: Bearer TOKEN"
```

### Provision an Agent

```bash
curl -X POST http://localhost:3100/api/v1/provision \
  -H "Authorization: Bearer TOKEN" \
  -H "Content-Type: application/json" \
  -d '{"agentId":"my-agent","displayName":"My Agent","capabilities":["sms","voice","email"]}'
```

---

## 6. MCP Connection

### SSE Transport

Your AI agent connects via the MCP protocol over Server-Sent Events:

```
GET http://localhost:3100/sse?token=AGENT_TOKEN&agentId=my-agent
```

### Node.js Example

```javascript
import { Client } from "@modelcontextprotocol/sdk/client/index.js";
import { SSEClientTransport } from "@modelcontextprotocol/sdk/client/sse.js";

const transport = new SSEClientTransport(
  new URL("http://localhost:3100/sse?token=YOUR_TOKEN&agentId=my-agent")
);

const client = new Client({ name: "my-agent", version: "1.0.0" });
await client.connect(transport);

// List available tools
const tools = await client.listTools();
console.log(tools.tools.map(t => t.name));

// Send an SMS — agentId auto-detected from token, no need to pass it
const result = await client.callTool({
  name: "comms_send_message",
  arguments: {
    to: "+15559876543",
    body: "Hello from my AI agent!",
    channel: "sms"
  }
});
console.log(JSON.parse(result.content[0].text));
```

### Claude Desktop / Cursor Config

```json
{
  "mcpServers": {
    "butt-dial": {
      "url": "http://localhost:3100/sse?token=YOUR_TOKEN&agentId=my-agent"
    }
  }
}
```

---

## Feature Reference

Every feature is available through both REST and MCP. Agent tokens auto-detect `agentId` — you don't need to pass it.

### Communication

| What | REST Endpoint | MCP Tool |
|------|--------------|----------|
| Send SMS / email / WhatsApp / LINE | `POST /send-message` | `comms_send_message` |
| Make an AI voice call | `POST /make-call` | `comms_make_call` |
| Call someone on your behalf | `POST /call-on-behalf` | `comms_call_on_behalf` |
| Send a TTS voice message | `POST /send-voice-message` | `comms_send_voice_message` |
| Transfer a live call | `POST /transfer-call` | `comms_transfer_call` |
| Get waiting messages | `GET /waiting-messages` | `comms_get_waiting_messages` |
| Send verification code | — | `comms_send_otp` |
| Verify a code | — | `comms_verify_otp` |

### Agent Management

| What | REST Endpoint | MCP Tool |
|------|--------------|----------|
| Check channel status | `GET /channel-status` | `comms_get_channel_status` |
| Provision agent (admin) | `POST /provision` | `comms_provision_channels` |
| Remove agent (admin) | `POST /deprovision` | `comms_deprovision_channels` |
| Full onboarding (admin) | `POST /onboard` | `comms_onboard_customer` |
| Set rate limits (admin) | `POST /agent-limits` | `comms_set_agent_limits` |
| Expand agent pool (admin) | — | `comms_expand_agent_pool` |
| Register provider (admin) | — | `comms_register_provider` |

### Billing & Usage

| What | REST Endpoint | MCP Tool |
|------|--------------|----------|
| Usage stats | `GET /usage` | `comms_get_usage_dashboard` |
| Billing summary | `GET /billing` | `comms_get_billing_summary` |
| Set billing config (admin) | `POST /billing/config` | `comms_set_billing_config` |

### Compliance

| What | MCP Tool |
|------|----------|
| Record contact consent | `comms_record_consent` |
| Revoke consent | `comms_revoke_consent` |
| Check consent status | `comms_check_consent` |

### System

| What | REST Endpoint | MCP Tool |
|------|--------------|----------|
| Health check | `GET /health` | `comms_ping` |
| OpenAPI spec | `GET /openapi.json` | — |
| Integration guide | `GET /integration-guide` | — |
| Bridge calls (admin) | — | `comms_bridge_call` |
| Create organization | — | `comms_create_organization` |
| List organizations | — | `comms_list_organizations` |

---

## 7. Channels

### SMS
- **Provider:** Twilio
- **Outbound:** `comms_send_message` with `channel: "sms"`
- **Inbound:** Auto-configured webhook at `/webhooks/:agentId/sms`
- **Requirements:** `TWILIO_ACCOUNT_SID`, `TWILIO_AUTH_TOKEN`, a phone number

### Voice
- **Provider:** Twilio ConversationRelay
- **Outbound:** `comms_make_call` — starts live AI conversation
- **Inbound:** Webhook at `/webhooks/:agentId/voice` + WebSocket
- **Requirements:** Same as SMS + `WEBHOOK_BASE_URL` (public HTTPS)

### Email
- **Provider:** Resend
- **Outbound:** `comms_send_message` with `channel: "email"`
- **Inbound:** Configure webhook in Resend dashboard → `/webhooks/:agentId/email`
- **Requirements:** `RESEND_API_KEY`, verified domain

### WhatsApp
- **Provider:** Twilio WhatsApp API
- **Outbound:** `comms_send_message` with `channel: "whatsapp"`
- **Inbound:** Auto-configured webhook at `/webhooks/:agentId/whatsapp`
- **Requirements:** Twilio WhatsApp sandbox or verified sender

### LINE
- **Provider:** LINE Messaging API
- **Outbound:** `comms_send_message` with `channel: "line"`
- **Inbound:** Configure webhook in LINE Console
- **Requirements:** `LINE_CHANNEL_ACCESS_TOKEN`, `LINE_CHANNEL_SECRET`

---

## 8. Going Live

1. **Add real provider credentials** — Twilio, Resend, etc. via the Settings tab or `.env`
2. **Set `DEMO_MODE=false`** in `.env`
3. **Set a public `WEBHOOK_BASE_URL`** for inbound messages
4. **Provision your agent** with real channels
5. Real messages start flowing

For community/enterprise editions, accounts are auto-approved. For SaaS, admin review is required.

---

## 9. Message Handling — Privacy-First Design

The server does **not** store messages by default. It's infrastructure — conversation memory belongs to your agent.

### What Gets Stored

| Scenario | Stored? | Where |
|----------|---------|-------|
| Successful outbound send | No | Only a usage log entry (count + cost, no content) |
| Successful inbound delivery | No | Forwarded to your agent's callback, not stored |
| Failed outbound send | Yes | `dead_letters` table — so you can retry |
| Inbound when agent offline | Yes | `dead_letters` table — delivered when agent reconnects |

### Dead Letter Queue

When a message can't be delivered, it's saved in the `dead_letters` table with:
- Channel, direction, from/to addresses
- Message body and any media URL
- Reason: `agent_offline`, `send_failed`, or `provider_error`
- Original request payload (so you can retry failed sends)

### Fetching Pending Messages

When your agent connects (or reconnects), call `comms_get_waiting_messages` to get any messages that arrived while offline. **Fetching automatically acknowledges them** — no separate acknowledge step needed.

Acknowledged dead letters are auto-purged after 7 days (configurable via `DEAD_LETTER_RETENTION_DAYS`).

### Your Agent's Responsibility

Since the server doesn't store conversation history, **your agent must manage its own memory**. If your agent needs to recall past conversations, store them in your own database. The server only handles delivery — not persistence.

---

## 10. Troubleshooting

| Problem | Fix |
|---------|-----|
| Can't connect to `/sse` | Check server is running: `curl http://localhost:3100/health` |
| Auth errors | Verify token is correct. In demo mode, set `DEMO_MODE=true` |
| No inbound messages | Set `WEBHOOK_BASE_URL` to a public URL (use ngrok for dev) |
| Rate limit errors | Use `/api/v1/usage` to check limits, increase via admin panel |
| Sandbox replies not appearing | Check if LLM key is configured. Set `SANDBOX_LLM_ENABLED=true` |
| Build errors | Run `npm run build` and check TypeScript output |

### Health Check

```bash
curl http://localhost:3100/health
# {"status":"ok","uptime":...,"version":"1.0.0"}
```

### Logs

The server outputs structured JSON logs. Filter by event type:
```bash
node dist/index.js 2>&1 | grep send_message_success
```

---

## Environment Variables Reference

### Required

| Variable | Description |
|----------|-------------|
| `PORT` | Server port (default: 3100) |

### Providers

| Variable | Description |
|----------|-------------|
| `TWILIO_ACCOUNT_SID` | Twilio account SID |
| `TWILIO_AUTH_TOKEN` | Twilio auth token |
| `RESEND_API_KEY` | Resend email API key |
| `ELEVENLABS_API_KEY` | ElevenLabs TTS (optional, free Edge TTS default) |
| `ANTHROPIC_API_KEY` | For answering machine + sandbox replies |
| `OPENAI_API_KEY` | Alternative LLM + TTS |

### Security

| Variable | Description |
|----------|-------------|
| `ORCHESTRATOR_SECURITY_TOKEN` | Super-admin token |
| `WEBHOOK_BASE_URL` | Public URL for webhooks |
| `DEMO_MODE` | `true` for mock providers |

### Sandbox

| Variable | Default | Description |
|----------|---------|-------------|
| `SANDBOX_LLM_ENABLED` | `true` | Enable simulated replies |
| `SANDBOX_LLM_ENDPOINT` | — | Custom OpenAI-compatible endpoint |
| `SANDBOX_REPLY_DELAY_MS` | `2000` | Delay before reply (ms) |

### Edition

| Variable | Default | Description |
|----------|---------|-------------|
| `EDITION` | `community` | `community`, `enterprise`, or `saas` |
